---
date: 2025-10-11T14:48:21+09:00
title: "FastAPI + LangChainìœ¼ë¡œ 30ë¶„ ë§Œì— ë‚˜ë§Œì˜ RAG ì±—ë´‡ ë§Œë“¤ê¸°"
description: "FastAPIì™€ LangChainì„ í™œìš©í•´ 30ë¶„ ë§Œì— RAG ì±—ë´‡ì„ êµ¬ì¶•í•˜ëŠ” ì‹¤ì „ ê°€ì´ë“œì…ë‹ˆë‹¤. ë¬¸ì„œ ì„ë² ë”©ë¶€í„° API êµ¬ì¶•, ì„±ëŠ¥ ìµœì í™”ê¹Œì§€ ë‹¨ê³„ë³„ë¡œ ì‹¤ìš©ì ì¸ ì½”ë“œì™€ íŒì„ ì œê³µí•©ë‹ˆë‹¤."
categories:
  - AI & ML
tags:
  - FastAPI
  - LangChain
  - RAG
  - ì±—ë´‡
  - ë²¡í„°DB
---

> FastAPIì™€ LangChainì„ í™œìš©í•´ 30ë¶„ ë§Œì— RAG ì±—ë´‡ì„ êµ¬ì¶•í•˜ëŠ” ì‹¤ì „ ê°€ì´ë“œì…ë‹ˆë‹¤. ë¬¸ì„œ ì„ë² ë”©ë¶€í„° API êµ¬ì¶•, ì„±ëŠ¥ ìµœì í™”ê¹Œì§€ ë‹¨ê³„ë³„ë¡œ ì‹¤ìš©ì ì¸ ì½”ë“œì™€ íŒì„ ì œê³µí•©ë‹ˆë‹¤.



<!-- more -->

## RAG ì±—ë´‡ì´ ë­ê¸¸ë˜ 30ë¶„ì´ë©´ ë§Œë“¤ ìˆ˜ ìˆë‹¤ê³ ?

RAG(Retrieval-Augmented Generation)ëŠ” ìµœê·¼ AI ì±—ë´‡ì˜ ê²Œì„ ì²´ì¸ì €ë¡œ ë– ì˜¤ë¥´ê³  ìˆìŠµë‹ˆë‹¤. ê°„ë‹¨íˆ ë§í•˜ë©´, ì™¸ë¶€ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•´ì„œ ê·¸ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë°©ì‹ì´ì—ìš”. ChatGPTê°€ í•™ìŠµí•˜ì§€ ì•Šì€ ì—¬ëŸ¬ë¶„ íšŒì‚¬ì˜ ë‚´ë¶€ ë¬¸ì„œë‚˜ ìµœì‹  ì •ë³´ë„ ì²™ì²™ ë‹µë³€í•  ìˆ˜ ìˆê²Œ ë˜ëŠ” ê±°ì£ .

FastAPIëŠ” Python ê¸°ë°˜ì˜ ë¹ ë¥´ê³  í˜„ëŒ€ì ì¸ ì›¹ í”„ë ˆì„ì›Œí¬ì´ê³ , LangChainì€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ì‰½ê²Œ ë§Œë“¤ì–´ì£¼ëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ì´ ë‘˜ì„ ì¡°í•©í•˜ë©´ ìƒê°ë³´ë‹¤ í›¨ì”¬ ê°„ë‹¨í•˜ê²Œ í”„ë¡œë•ì…˜ ë ˆë²¨ì˜ ì±—ë´‡ì„ ë§Œë“¤ ìˆ˜ ìˆì–´ìš”.

**í•µì‹¬ í¬ì¸íŠ¸**: RAGëŠ” 'ê²€ìƒ‰ + ìƒì„±'ì˜ ì¡°í•©ì´ë©°, ì‚¬ì „ í•™ìŠµë˜ì§€ ì•Šì€ ë°ì´í„°ë¡œë„ ì •í™•í•œ ë‹µë³€ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

## í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ì™€ ê¸°ë³¸ ì„¤ì •

ë¨¼ì € í•„ìš”í•œ íŒ¨í‚¤ì§€ë“¤ì„ ì„¤ì¹˜í•´ë³¼ê¹Œìš”? í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.

bash
pip install fastapi uvicorn langchain langchain-openai chromadb pypdf sentence-transformers


ê° ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ì—­í• ì„ ê°„ë‹¨íˆ ì„¤ëª…í•˜ë©´:
- **fastapi**: API ì„œë²„ êµ¬ì¶•
- **uvicorn**: ASGI ì„œë²„ (FastAPI ì‹¤í–‰ìš©)
- **langchain**: LLM ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
- **chromadb**: ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ (ë¬¸ì„œ ê²€ìƒ‰ìš©)
- **pypdf**: PDF ë¬¸ì„œ íŒŒì‹±
- **sentence-transformers**: í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±

í™˜ê²½ë³€ìˆ˜ë¡œ OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”:

bash
export OPENAI_API_KEY='your-api-key-here'


ğŸ’¡ **íŒ**: `.env` íŒŒì¼ì„ ë§Œë“¤ì–´ì„œ `python-dotenv`ë¡œ ê´€ë¦¬í•˜ë©´ ë” ì•ˆì „í•˜ê³  í¸ë¦¬í•©ë‹ˆë‹¤!

## ë¬¸ì„œ ì„ë² ë”©ê³¼ ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶•í•˜ê¸°

RAGì˜ í•µì‹¬ì€ ë¬¸ì„œë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•´ì„œ ì €ì¥í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ë¹ ë¥´ê²Œ ì°¾ì„ ìˆ˜ ìˆì–´ìš”.

python
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import Chroma

# ë¬¸ì„œ ë¡œë“œ
loader = PyPDFLoader("your_document.pdf")
documents = loader.load()

# ë¬¸ì„œë¥¼ ì ì ˆí•œ í¬ê¸°ë¡œ ë¶„í• 
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200
)
splits = text_splitter.split_documents(documents)

# ì„ë² ë”© ëª¨ë¸ ì„¤ì • (í•œêµ­ì–´ëŠ” multilingual ëª¨ë¸ ì¶”ì²œ)
embeddings = HuggingFaceEmbeddings(
    model_name="jhgan/ko-sroberta-multitask"
)

# ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
vectorstore = Chroma.from_documents(
    documents=splits,
    embedding=embeddings,
    persist_directory="./chroma_db"
)


**ì¤‘ìš”í•œ ì„¤ì • í¬ì¸íŠ¸**:
- `chunk_size`: ë„ˆë¬´ í¬ë©´ ê²€ìƒ‰ ì •í™•ë„ê°€ ë–¨ì–´ì§€ê³ , ë„ˆë¬´ ì‘ìœ¼ë©´ ë§¥ë½ì´ ì†ì‹¤ë©ë‹ˆë‹¤. 1000ì ì •ë„ê°€ ì ë‹¹í•´ìš”.
- `chunk_overlap`: ì²­í¬ ê°„ ì¤‘ë³µì„ ë‘ì–´ ë¬¸ë§¥ ë‹¨ì ˆì„ ë°©ì§€í•©ë‹ˆë‹¤.
- í•œêµ­ì–´ ë¬¸ì„œë¼ë©´ í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì •í™•ë„ê°€ í›¨ì”¬ ë†’ìŠµë‹ˆë‹¤.

## FastAPIë¡œ ì±—ë´‡ API êµ¬ì¶•í•˜ê¸°

ì´ì œ ì‹¤ì œ APIë¥¼ ë§Œë“¤ì–´ë³¼ ì°¨ë¡€ì…ë‹ˆë‹¤. FastAPIì˜ ë¹„ë™ê¸° ì²˜ë¦¬ë¥¼ í™œìš©í•˜ë©´ ì—¬ëŸ¬ ìš”ì²­ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆì–´ìš”.

python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI

app = FastAPI(title="RAG Chatbot API")

# ìš”ì²­ ëª¨ë¸ ì •ì˜
class ChatRequest(BaseModel):
    question: str
    top_k: int = 3

# LLM ë° retriever ì„¤ì •
llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)
retriever = vectorstore.as_retriever(search_kwargs={"k": 3})

# RAG ì²´ì¸ êµ¬ì„±
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=retriever,
    return_source_documents=True
)

@app.post("/chat")
async def chat(request: ChatRequest):
    try:
        result = qa_chain({"query": request.question})
        
        return {
            "answer": result["result"],
            "sources": [
                {"content": doc.page_content, "page": doc.metadata.get("page")}
                for doc in result["source_documents"]
            ]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health_check():
    return {"status": "healthy"}


ì„œë²„ ì‹¤í–‰ì€ ê°„ë‹¨í•©ë‹ˆë‹¤:

bash
uvicorn main:app --reload --port 8000


ğŸ’¡ **í”„ë¡œë•ì…˜ íŒ**: `chain_type="stuff"`ëŠ” ê°„ë‹¨í•˜ì§€ë§Œ, ë¬¸ì„œê°€ ë§ì„ ë•ŒëŠ” `map_reduce`ë‚˜ `refine` ë°©ì‹ì„ ê³ ë ¤í•´ë³´ì„¸ìš”. ê°ê° ì¥ë‹¨ì ì´ ìˆìŠµë‹ˆë‹¤.

## ì‹¤ì „ í…ŒìŠ¤íŠ¸ì™€ ì„±ëŠ¥ ê°œì„  í¬ì¸íŠ¸

ì´ì œ ë§Œë“  APIë¥¼ í…ŒìŠ¤íŠ¸í•´ë³¼ê¹Œìš”?

bash
curl -X POST "http://localhost:8000/chat" \
  -H "Content-Type: application/json" \
  -d '{"question": "ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš©ì´ ë­”ê°€ìš”?"}'


**ì„±ëŠ¥ ê°œì„ ì„ ìœ„í•œ ì²´í¬ë¦¬ìŠ¤íŠ¸**:

1. **ìºì‹± í™œìš©**: ë™ì¼í•œ ì§ˆë¬¸ì— ëŒ€í•´ ë§¤ë²ˆ ê²€ìƒ‰í•˜ì§€ ë§ê³  Redis ë“±ìœ¼ë¡œ ìºì‹±í•˜ì„¸ìš”.
2. **ì„ë² ë”© ëª¨ë¸ ìµœì í™”**: ìš©ëŸ‰ê³¼ ì†ë„ì˜ íŠ¸ë ˆì´ë“œì˜¤í”„ë¥¼ ê³ ë ¤í•´ì„œ ì„ íƒí•˜ì„¸ìš”. ì„œë¹„ìŠ¤ ì´ˆê¸°ì—” ê°€ë²¼ìš´ ëª¨ë¸ë¡œ ì‹œì‘í•˜ëŠ” ê²Œ ì¢‹ìŠµë‹ˆë‹¤.
3. **ë¹„ë™ê¸° ì²˜ë¦¬**: LangChainì˜ async ë©”ì„œë“œ(`arun`, `ainvoke`)ë¥¼ í™œìš©í•˜ë©´ ì²˜ë¦¬ ì†ë„ê°€ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤.
4. **í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§**: `RetrievalQA`ì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ì»¤ìŠ¤í„°ë§ˆì´ì§•í•´ì„œ ë‹µë³€ í’ˆì§ˆì„ ë†’ì¼ ìˆ˜ ìˆì–´ìš”.

python
from langchain.prompts import PromptTemplate

prompt_template = """ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•´ì„œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
ë‹µë³€ì€ ì¹œì ˆí•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

{context}

ì§ˆë¬¸: {question}
ë‹µë³€:"""

PROMPT = PromptTemplate(
    template=prompt_template, 
    input_variables=["context", "question"]
)


**ì‹¤ì „ ì£¼ì˜ì‚¬í•­**: ë²¡í„° DBëŠ” ì´ˆê¸° ë¡œë”© ì‹œê°„ì´ ìˆìœ¼ë‹ˆ, ì„œë²„ ì‹œì‘ ì‹œ ë¯¸ë¦¬ ë¡œë“œí•´ë‘ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ë˜í•œ ì‹¤ì‹œê°„ìœ¼ë¡œ ë¬¸ì„œê°€ ì—…ë°ì´íŠ¸ëœë‹¤ë©´ ì¦ë¶„ ì—…ë°ì´íŠ¸ ì „ëµì„ ìˆ˜ë¦½í•´ì•¼ í•©ë‹ˆë‹¤.

30ë¶„ì´ë©´ ê¸°ë³¸ êµ¬ì¡°ëŠ” ì™„ì„±ë˜ì§€ë§Œ, ì‹¤ì œ ì„œë¹„ìŠ¤ì— ë°°í¬í•˜ë ¤ë©´ ì—ëŸ¬ í•¸ë“¤ë§, ë¡œê¹…, ëª¨ë‹ˆí„°ë§ ë“±ì„ ì¶”ê°€ë¡œ êµ¬í˜„í•´ì•¼ í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ ì´ ê¸°ë³¸ êµ¬ì¡°ë§Œìœ¼ë¡œë„ ì¶©ë¶„íˆ ê°•ë ¥í•œ RAG ì±—ë´‡ì˜ í”„ë¡œí† íƒ€ì…ì„ ë§Œë“¤ ìˆ˜ ìˆë‹µë‹ˆë‹¤!

---

*ì´ ê¸€ì€ AIê°€ ìë™ìœ¼ë¡œ ì‘ì„±í–ˆìŠµë‹ˆë‹¤.*
